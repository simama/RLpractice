{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dagger RL Simple Implementation  \n",
    "Dagger is a reinforcement learning algorithm for imitation learning/behaviour cloning. Introdiced in paper https://www.cs.cmu.edu/~sross1/publications/Ross-AIStats11-NoRegret.pdf  \n",
    "It uses initial expert knowledge (usually human labeled data) to perform surprevised learning of agent's policy (mapping from observations to actions). Main trick in Dagger is that after agent learns initial policy (from expert data), it uses that policy to act in real environemnt and stores those experiences (observations). These real observations are then passed to expert to be labeled (add expert's actions), and are added to the training set. Then agent policy is trained again, this time on the new augmented data set, and cycle is repeated.        \n",
    "  \n",
    "Main trick in Dagger is dataset augmentation from agent's own experince. Inital expert dataset is limited and it is very likely that agent will diverge from the expert's path and encounter new states. Initial policy is almost useless in those new situations. By obtaining expert labels for those new observations and retraining the policy, agent becomes more robust to path perturbations.  \n",
    "  \n",
    "This implementation is made for UC Berkely course CS 294 Deep Reinforcement Learning. It is a naive implementation (still unfinished curentlly) by extending previous ordinary imitation learning technique, uses provided expert policy for gathering expert's dataset, and acts in MuJoCo environment.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import tf_util\n",
    "import load_policy\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Netowrk definition \n",
    "\n",
    "class Network():\n",
    "    def __init__(self, input_dim, action_dim, hidden1_units, hidden2_units, regularization = False, beta = 0.01):\n",
    "        \"\"\"Network definition\"\"\"\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.h1_num = hidden1_units\n",
    "        self.h2_num = hidden2_units\n",
    "        self.input_observations = tf.placeholder(tf.float32, shape=(None,self.input_dim))\n",
    "        self.action_labels = tf.placeholder(tf.float32, shape=(None,self.action_dim))\n",
    "\n",
    "        self.w1 = tf.Variable(tf.truncated_normal([self.input_dim, self.h1_num],\n",
    "                                                  stddev=1.0 / math.sqrt(float(self.input_dim))),name='w1')\n",
    "        self.b1 = tf.Variable(tf.zeros(self.h1_num),name='b1')\n",
    "        self.h1 = tf.nn.relu(tf.matmul(self.input_observations,self.w1) + self.b1)\n",
    "\n",
    "        self.w2 = tf.Variable(tf.truncated_normal([self.h1_num, self.h2_num],\n",
    "                                             stddev=1.0 / math.sqrt(float(self.h1_num))),name='w2')\n",
    "        self.b2 = tf.Variable(tf.zeros(self.h2_num),name='b2')\n",
    "        self.h2 = tf.nn.relu(tf.matmul(self.h1,self.w2) + self.b2)\n",
    "\n",
    "        self.w3 = tf.Variable(tf.truncated_normal([self.h2_num, self.action_dim],\n",
    "                                             stddev=1.0 / math.sqrt(float(self.h2_num))),name='w3')\n",
    "        self.b3 = tf.Variable(tf.zeros(self.action_dim),name='b3')\n",
    "        self.output = tf.matmul(self.h2,self.w3) + self.b3\n",
    "\n",
    "        self.error = tf.reduce_mean(tf.pow(tf.subtract(self.output,self.action_labels),2))\n",
    "        if regularization:\n",
    "            self.regularizers = tf.nn.l2_loss(self.w1) + tf.nn.l2_loss(self.w2) + tf.nn.l2_loss(self.w3)\n",
    "            self.error = self.error + beta * self.regularizers\n",
    "\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(self.error)\n",
    "\n",
    "    def train(self, sess, saver, train_data, training_epochs, batch_size):\n",
    "        \"\"\"Supervised training of agent network\"\"\"\n",
    "        \n",
    "        total_batch = int(len(train_data)/batch_size)\n",
    "        for epoch in xrange(training_epochs):\n",
    "            batch_count = 0\n",
    "            avg_cost = 0.\n",
    "      \n",
    "            # Loop over all batches\n",
    "            for i in xrange(total_batch):\n",
    "                next_batch = random.sample(train_data, batch_size)\n",
    "                next_batch = zip(*next_batch)\n",
    "                batch_x = next_batch[0]\n",
    "                batch_y = np.asarray(next_batch[1])\n",
    "                batch_y = batch_y.reshape((batch_size,self.action_dim))\n",
    "\n",
    "                # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                _, c = sess.run([self.optimizer, self.error], \n",
    "                                feed_dict={self.input_observations: batch_x, self.action_labels: batch_y})\n",
    "                \n",
    "                # Compute average loss\n",
    "                avg_cost += c / total_batch\n",
    "                if i % 20000 == 0:\n",
    "                    print(\"Batch number {:d}\".format(i))\n",
    "                    #print(\"Step {} | Average cost {}\".format(i, avg_cost))\n",
    "            \n",
    "            # Display logs per epoch step\n",
    "            print(\"Epoch: {:04d}, cost = {:.9f}\".format(epoch+1, avg_cost))\n",
    "            \n",
    "        print \"Optimization Finished!\"\n",
    "        saver.save(sess, path + '/' + environment + '.cptk')\n",
    "        print (\"Model Saved\")\n",
    "        \n",
    "    def run(self, sess, saver, env, data_mean, num_rollouts = 20, render = False, load_model = True):\n",
    "        \"\"\"Run policy on real observations\"\"\"\n",
    "       \n",
    "        returns = []\n",
    "        observations = []\n",
    "        max_step = env.spec.timestep_limit\n",
    "        \"\"\"\n",
    "        if load_model:\n",
    "            print('Loading Model...')\n",
    "            ckpt = tf.train.get_checkpoint_state(path)\n",
    "            saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "        else: \n",
    "            sess.close()\n",
    "        \"\"\"\n",
    "        for i in xrange(num_rollouts):\n",
    "            if i % 10 == 0:\n",
    "                print('iter', i)\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            totalr = 0.\n",
    "            steps = 0\n",
    "            while not done:\n",
    "                observations.append(obs)\n",
    "                obs = obs.reshape((1,self.input_dim))\n",
    "                obs -= data_mean\n",
    "                action = sess.run(self.output, feed_dict={self.input_observations: obs})\n",
    "                obs, r, done, _ = env.step(action)\n",
    "                totalr += r\n",
    "                steps += 1\n",
    "                if render:\n",
    "                    env.render()\n",
    "                if steps >= max_step:\n",
    "                    break\n",
    "            returns.append(totalr)\n",
    "\n",
    "        print('returns', returns)\n",
    "        print('mean return', np.mean(returns))\n",
    "        print('std of return', np.std(returns))\n",
    "        \n",
    "        self.agent_data = {'observations': np.array(observations)}\n",
    "        with open(\"Hopper-v1\" + '_agent_data.pickle', 'wb') as handle:\n",
    "            pickle.dump(self.agent_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            print(\"Agent data pickled successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def expert(expert_policy_file):\n",
    "    print('loading and building expert policy')\n",
    "    policy_fn = load_policy.load_policy(expert_policy_file)\n",
    "    print('loaded and built')\n",
    "    \n",
    "    with open(\"Hopper-v1\" + '_agent_data.pickle', 'rb') as handle:\n",
    "        agent_data = pickle.load(handle)\n",
    "        print(agent_data['observations'].shape)\n",
    "        \n",
    "    actions = []    \n",
    "    observations = agent_data['observations']\n",
    "    #print(type(observations[0]), len(observations), observations[0])\n",
    "    with tf.Session():\n",
    "        tf_util.initialize()\n",
    "\n",
    "        for i in xrange(len(observations)):\n",
    "            action = policy_fn(np.asarray(observations[i][None,:]))\n",
    "            #print(action.shape)\n",
    "            actions.append(action)\n",
    "    print(\"Done\")        \n",
    "    return actions, observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#actions, observations = expert(\"experts/Hopper-v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(np.asarray(actions).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open(\"Hopper-v1\" + '_expert_data.pickle', 'rb') as handle:\n",
    "#        train_data = pickle.load(handle)\n",
    "#print(train_data['observations'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(train_data, data_mean = []):\n",
    "    \"\"\"Data preprocessing - mean substraction and normalization\"\"\"\n",
    "    \n",
    "    if not any(data_mean):\n",
    "        data_mean = np.mean(train_data['observations'], axis = 0)\n",
    "    train_data['observations'] -= data_mean\n",
    "    input_dim = train_data['observations'].shape[1]\n",
    "    action_dim = train_data['actions'].shape[2]\n",
    "    data_combined = zip(train_data['observations'], train_data['actions'])\n",
    "    return data_mean, input_dim, action_dim, data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(num_cycles, environment):    \n",
    "    with open(\"Hopper-v1\" + '_expert_data.pickle', 'rb') as handle:\n",
    "        train_data = pickle.load(handle)\n",
    "    data_mean, input_dim, action_dim, data_combined = data_preprocessing(train_data)\n",
    "    print(\"Initial data mean is: {}\".format(data_mean))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        agent = Network(input_dim,action_dim, hidden1_units, hidden2_units)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        for cycle in xrange(num_cycles):            \n",
    "            agent.train(sess, saver, data_combined, training_epochs, batch_size)\n",
    "            agent.run(sess, saver, environment, data_mean, num_rollouts, load_model = False)\n",
    "            #break\n",
    "            expert_actions, observations = expert(\"experts/Hopper-v1.pkl\")\n",
    "            train_data['actions'] = np.concatenate((train_data['actions'], expert_actions), axis=0)\n",
    "            print(train_data['actions'].shape)\n",
    "            train_data['observations'] = np.concatenate((train_data['observations'], observations), axis=0)\n",
    "            print(train_data['observations'].shape)\n",
    "            _, input_dim, action_dim, data_combined = data_preprocessing(train_data, data_mean)\n",
    "            print(\"Data mean is: {}\".format(data_mean))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-28 17:10:10,929] Making new env: Hopper-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data mean is: [  1.40310727e+00  -6.88182004e-03  -1.11049251e-01  -5.71447489e-01\n",
      "   2.88128503e-01   2.78367951e+00   4.64378410e-02  -4.14444474e-04\n",
      "  -8.67950539e-03  -1.02232249e-01   1.68187284e-01]\n",
      "Batch number 0\n",
      "Batch number 20000\n",
      "Batch number 40000\n",
      "Batch number 60000\n",
      "Batch number 80000\n",
      "Epoch: 0001, cost = 0.001099784\n",
      "Optimization Finished!\n",
      "Model Saved\n",
      "('iter', 0)\n",
      "('iter', 10)\n",
      "('iter', 20)\n",
      "('iter', 30)\n",
      "('iter', 40)\n",
      "('iter', 50)\n",
      "('iter', 60)\n",
      "('iter', 70)\n",
      "('iter', 80)\n",
      "('iter', 90)\n",
      "('iter', 100)\n",
      "('iter', 110)\n",
      "('iter', 120)\n",
      "('iter', 130)\n",
      "('iter', 140)\n",
      "('iter', 150)\n",
      "('iter', 160)\n",
      "('iter', 170)\n",
      "('iter', 180)\n",
      "('iter', 190)\n",
      "('returns', [3776.6603685111959, 3780.8849023811154, 3771.8051972639805, 3773.1690911097544, 3779.2478158351205, 3772.015315135995, 3769.8493120141893, 3774.2872844376388, 3779.4212488159301, 3779.3366561863263, 3773.0865570657356, 3776.135907079818, 3778.2653662720154, 3779.6122731312958, 3778.5714278417317, 3782.6171420786277, 3784.2834198316159, 3778.1222637692081, 3774.7121666706448, 3776.8101374988987, 3780.7292185723149, 3779.8275263433629, 3775.186691126019, 3777.32377363553, 3777.0056490415614, 3775.3172617567034, 3784.2512529763544, 3773.1075948377047, 3774.6278039557969, 3776.5329019778383, 3780.2080804685534, 3776.9312838304254, 3782.5293071355286, 3780.6283034713806, 3771.1198429979272, 3774.4365232550881, 3779.4965560733503, 3780.6011859989953, 3779.7107128555281, 3781.0557332320627, 3780.5322064310089, 3776.8406291086253, 3771.3595403140062, 3780.2979729893209, 3777.7988478384564, 3778.2580797230521, 3779.250330392787, 3774.5566338231079, 3786.4030986006924, 3782.1597810080671, 3785.3678765711143, 3781.2982400987353, 3777.1742755706368, 3771.2710083882116, 3776.430154197164, 3774.5018081465842, 3778.8497352367353, 3777.3440744199575, 3783.4201860609792, 3779.2430468309526, 3780.7971399616263, 3771.9449213972157, 3788.3864693002452, 3782.084564658895, 3771.7946306692556, 3781.0694668284254, 3777.98173893889, 3778.3717704152182, 3777.9089237559401, 3774.0127171179911, 3777.1317886103493, 3777.6907383227071, 3778.4051155073739, 3776.3182625410122, 3778.6673515075454, 3777.6289741265068, 3775.3961219398134, 3780.0069986742938, 3782.3417033808514, 3782.2678156327092, 3774.3629933531915, 3770.9370016438161, 3771.9872585375874, 3787.5872862475376, 3779.4199277499638, 3778.8882123884878, 3781.6174118855606, 3778.4052036059788, 3780.9452696987478, 3777.7987541344428, 3776.5217917535024, 3776.0776654098077, 3773.3108276865664, 3778.0084098804296, 3782.3246576210468, 3770.5707027279018, 3772.1331957085317, 3774.4032751687796, 3772.7893536386946, 3779.9329315525588, 3789.5583336396726, 3776.4244571972017, 3776.5741668707224, 3778.2985466790115, 3777.6188903687816, 3783.3526226905901, 3774.7602885564725, 3781.4484857840316, 3773.4908066165153, 3779.6099834019315, 3778.779646002487, 3781.8960667854258, 3769.9130836731674, 3773.988797658159, 3779.8691501960552, 3777.454874318561, 3777.4550520711391, 3768.5416496664766, 3776.451122650667, 3782.4952049104118, 3785.7551268906, 3779.4395689449216, 3773.9602774492068, 3785.0000168817837, 3780.7708317601036, 3782.4365675310169, 3773.8253940353388, 3776.3052409269617, 3774.092348914492, 3777.7030515700603, 3781.0045153365731, 3779.9428813633658, 3775.7962105009792, 3778.221950355457, 3782.3423387395137, 3774.4859568078327, 3778.9255963005726, 3778.4583017144641, 3781.1904727057558, 3775.8687042753327, 3780.0801471748341, 3776.5584004871739, 3780.9183461781831, 3774.6453953410137, 3776.350875399934, 3777.5325436378976, 3776.1846752471693, 3784.3872520660848, 3773.1604183584955, 3781.7580633119373, 3780.2603982320052, 3772.6249470088978, 3774.8964357908199, 3772.5108149341368, 3771.2411564239151, 3780.5712090662537, 3771.6741088146932, 3774.1725165861239, 3780.431326675206, 3778.832727089135, 3772.6506876401399, 3774.0511982314656, 3777.4173213337704, 3779.6878024080411, 3774.692486117729, 3778.8999461945909, 3780.3790632952982, 3775.326219324073, 3773.9938269278855, 3778.3676324863659, 3777.4826399337826, 3783.5489503657063, 3773.7918779270267, 3773.1606798904827, 3778.0647155459892, 3774.1332068074289, 3781.7648178162058, 3781.692181790469, 3782.7714465692225, 3776.5752948909435, 3782.9614921863467, 3780.3773435603516, 3780.3868180822892, 3780.1348126101529, 3781.4802863396362, 3774.1653104785132, 3780.9721536606967, 3776.2403393089166, 3774.4661817335495, 3780.8731162215713, 3777.2042595919343, 3776.0023305312875, 3775.353811214773, 3778.4230624714064, 3775.457405721329, 3774.9194045055965, 3776.6230400399472, 3776.9289651108024, 3784.5412481851426, 3779.2011114557695])\n",
      "('mean return', 3777.8378537748767)\n",
      "('std of return', 3.8013245067424641)\n",
      "Agent data pickled successfully\n",
      "loading and building expert policy\n",
      "('obs', (1, 11), (1, 11))\n",
      "loaded and built\n",
      "(200000, 11)\n",
      "WARNING:tensorflow:From tf_util.py:91: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-28 17:13:05,905] From tf_util.py:91: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From tf_util.py:92: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-28 17:13:05,906] From tf_util.py:92: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "(10200000, 1, 3)\n",
      "(10200000, 11)\n",
      "Data mean is: [  1.40310727e+00  -6.88182004e-03  -1.11049251e-01  -5.71447489e-01\n",
      "   2.88128503e-01   2.78367951e+00   4.64378410e-02  -4.14444474e-04\n",
      "  -8.67950539e-03  -1.02232249e-01   1.68187284e-01]\n",
      "Batch number 0\n",
      "Batch number 20000\n",
      "Batch number 40000\n",
      "Batch number 60000\n",
      "Batch number 80000\n",
      "Batch number 100000\n",
      "Epoch: 0001, cost = 0.052559627\n",
      "Optimization Finished!\n",
      "Model Saved\n",
      "('iter', 0)\n",
      "('iter', 10)\n",
      "('iter', 20)\n",
      "('iter', 30)\n",
      "('iter', 40)\n",
      "('iter', 50)\n",
      "('iter', 60)\n",
      "('iter', 70)\n",
      "('iter', 80)\n",
      "('iter', 90)\n",
      "('iter', 100)\n",
      "('iter', 110)\n",
      "('iter', 120)\n",
      "('iter', 130)\n",
      "('iter', 140)\n",
      "('iter', 150)\n",
      "('iter', 160)\n",
      "('iter', 170)\n",
      "('iter', 180)\n",
      "('iter', 190)\n",
      "('returns', [223.7509269659931, 226.17714696447288, 226.09183705022397, 226.37806549148792, 225.44352345466734, 224.59023337809555, 228.14787647097046, 227.81240717691847, 229.42359590551769, 224.21406051083761, 226.28215050850656, 228.35925916018132, 228.83346152820204, 228.54278026169598, 228.51933067484399, 228.50345170902798, 224.69041713336037, 224.07409448746776, 229.34163482960233, 225.42006306037976, 226.41514582091378, 228.66369666359637, 227.7465109627895, 225.90033534505395, 229.30834895296218, 231.01972578619822, 225.93165246332384, 229.04174808355265, 226.48325879531581, 228.40681305344887, 230.69512933343643, 227.53198858980878, 225.34076707152357, 225.6987114483783, 231.33178423328539, 226.20950983752644, 226.34750490277358, 231.35094169464696, 229.21673918519701, 229.81525996246066, 223.97908999922737, 229.22318450410197, 228.6950558067287, 225.97217802172042, 230.11902013194694, 230.700431580817, 226.50172341625901, 227.11830978716824, 226.16000654877359, 226.20372829090275, 226.4139931084737, 226.27240268911413, 230.82491970466367, 228.03426836349132, 223.95571658292693, 231.05538615453884, 224.49226932528231, 229.83663491677626, 228.65088120588254, 227.1839531905577, 231.73817279306923, 232.47933336250227, 227.45025556067245, 228.40893953504437, 226.23487657456351, 229.93634209071112, 228.42575727876698, 229.92483733145676, 225.55058880942929, 224.13808846293597, 335.29233445495282, 226.39262629494215, 231.33462404387376, 230.94566278739441, 227.30326779270675, 225.21505596491528, 231.76467314228833, 227.52852918770574, 226.02483389877438, 225.84812846039532, 228.66261233321177, 227.64539644708191, 226.74570332465859, 225.25475075866541, 229.88694046445767, 227.78541314114807, 226.10881744181651, 224.65466842271653, 225.9607018826824, 229.76128486789622, 226.10573853945843, 229.29166357071048, 229.09081521053977, 229.46454347162884, 224.69324194803386, 230.8480837667972, 339.42668875466654, 224.49694139163083, 225.99021292117922, 225.47994322957507, 228.65412706656016, 229.83092740532948, 225.76658525063732, 226.34487916820487, 229.04176645475059, 229.87033338111587, 225.41666980321497, 224.78521769451558, 224.45318028620571, 227.22893144724765, 227.87111351585145, 229.24330787870278, 224.66471326754984, 225.94552052516579, 226.88698868033501, 225.42668241397811, 227.3784101579003, 233.60626550177258, 227.11328753595788, 229.13439598512224, 227.80978030000819, 224.66176815983968, 226.75085487022619, 227.958387938653, 227.82285586376236, 226.47717759830445, 230.06277528905682, 226.43479037650675, 226.00422351835149, 224.82572835823288, 226.36025293008055, 223.8355100469916, 229.11164300663611, 228.58143990081692, 227.05708962815706, 231.00546600427631, 227.42171484899933, 226.84047339611644, 226.33261001192355, 229.42534947738108, 227.25006406439141, 226.746728011784, 231.78986986204643, 227.80808273077847, 227.44658745196085, 225.2500912748929, 231.14750525546211, 224.86736716604617, 225.97976304735826, 228.5597181555211, 225.80197141765672, 229.93483236180944, 226.52300145029849, 225.45507186518054, 224.46907472060573, 228.71677589598431, 230.5274817445185, 228.77183955375338, 229.70878566218968, 225.07062101400984, 227.37289128873871, 227.92189184497616, 226.86437077667495, 226.68305118177992, 227.57070316541299, 226.58933049039442, 339.90294930448744, 226.78825196058503, 225.56857707205805, 226.87647799196188, 229.32713928852695, 230.36491488173081, 226.94428281035687, 227.84954186936534, 231.22379536581533, 225.48607040208364, 230.5467379866688, 230.80489204886146, 229.81500468417576, 232.30396710767943, 231.33138275319271, 228.78049449939579, 230.15281741547307, 225.72886294016365, 229.63254252678689, 228.83914992006063, 225.45864508709741, 226.04663635023167, 228.11729672651762, 227.42261297285441, 226.0621631315862, 224.92153473060847, 227.67291487794051, 232.06323719699418, 226.17592456739968, 226.81277908252093, 227.27899577164393, 227.13344071681828, 230.13407422621336, 227.51160348122852])\n",
      "('mean return', 229.28543255050704)\n",
      "('std of return', 13.607479337593588)\n",
      "Agent data pickled successfully\n",
      "loading and building expert policy\n",
      "('obs', (1, 11), (1, 11))\n",
      "loaded and built\n",
      "(21183, 11)\n",
      "WARNING:tensorflow:From tf_util.py:91: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-28 17:15:27,479] From tf_util.py:91: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From tf_util.py:92: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-28 17:15:27,480] From tf_util.py:92: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "(10221183, 1, 3)\n",
      "(10221183, 11)\n",
      "Data mean is: [  1.40310727e+00  -6.88182004e-03  -1.11049251e-01  -5.71447489e-01\n",
      "   2.88128503e-01   2.78367951e+00   4.64378410e-02  -4.14444474e-04\n",
      "  -8.67950539e-03  -1.02232249e-01   1.68187284e-01]\n",
      "Batch number 0\n",
      "Batch number 20000\n",
      "Batch number 40000\n",
      "Batch number 60000\n",
      "Batch number 80000\n",
      "Batch number 100000\n",
      "Epoch: 0001, cost = 0.051604189\n",
      "Optimization Finished!\n",
      "Model Saved\n",
      "('iter', 0)\n",
      "('iter', 10)\n",
      "('iter', 20)\n",
      "('iter', 30)\n",
      "('iter', 40)\n",
      "('iter', 50)\n",
      "('iter', 60)\n",
      "('iter', 70)\n",
      "('iter', 80)\n",
      "('iter', 90)\n",
      "('iter', 100)\n",
      "('iter', 110)\n",
      "('iter', 120)\n",
      "('iter', 130)\n",
      "('iter', 140)\n",
      "('iter', 150)\n",
      "('iter', 160)\n",
      "('iter', 170)\n",
      "('iter', 180)\n",
      "('iter', 190)\n",
      "('returns', [3.4499662302094256, 3.5130058702196427, 3.3650542097684699, 3.4195950043830678, 3.7021478837842117, 3.1092135676855301, 3.2557265803445681, 3.4006629664225612, 3.4926670461639735, 3.4613310346768658, 3.2172893112159877, 3.3917597525308087, 3.3582751652860905, 3.4599359128248284, 3.1996029117521414, 3.2961394072736128, 3.4522008552968204, 3.1318925062695988, 3.4333203012993252, 3.5359274568456809, 3.1805894066974325, 3.2696927066888533, 3.1772021824091339, 3.0964169032156938, 3.5494559815140558, 3.7964650957860862, 3.4285718966420617, 3.309430276840498, 3.1921576575800623, 3.4159566836900588, 3.2774247681144071, 3.1801494668982029, 3.2176181866110363, 3.2665581920185476, 3.3253197872490436, 3.1101806032656611, 3.2630090731773347, 3.3015228981515863, 3.0450964766280579, 3.1144812991501571, 3.668915294350537, 3.2136935582228041, 3.0930209026775577, 3.3474581116126476, 3.2796358705895905, 3.2744196987423617, 3.5141127724741885, 3.5173059023488285, 3.4194158077815042, 3.6071076997584495, 3.3862896509842937, 3.4061404860413593, 3.2517048595779237, 3.4920177171970925, 3.3811126528629125, 3.2147456826287244, 3.3359151762762753, 3.1273504782463615, 3.1381849306484666, 3.2596144602859067, 3.4894087916240397, 3.1197906391205157, 3.4205911023761013, 3.4601867617722437, 3.1506372689852156, 3.2068394696921807, 3.3974500820320386, 3.097528002790308, 3.4959177663829424, 3.4011891305172548, 3.3976585764919678, 3.4952336648409656, 3.4485803095525518, 3.5130047137368221, 3.1068429268805589, 3.2655471542457581, 3.4646850801866806, 3.3056784869335631, 3.3163536132265654, 3.1621420593005021, 3.3989936661725269, 3.5371776464909965, 3.4884791525072218, 3.4698732968952077, 3.1305920192659338, 3.2214109528162389, 3.264490166085078, 3.5392369085436961, 3.32756868337809, 3.2543675582115346, 3.2643586779092408, 3.4026837034548523, 3.5595657130347216, 3.3293772771319761, 3.1316511557057125, 3.5008794324623853, 3.4706393837639764, 3.3522620541989769, 3.3521546308371142, 3.1890488049533756, 3.2897802470397104, 3.3977071825437659, 3.3249642781184479, 3.4108287310976282, 3.137192783321928, 3.1929592430601477, 3.3909443303020383, 3.5067286050624684, 3.4622054639778872, 3.2912676716822333, 3.4040413611215619, 3.2878075850680997, 3.4952972621379135, 3.2767577849773115, 3.1551816368051626, 3.3894598734956056, 3.3557272176707111, 3.5509652282979358, 3.6032423071145012, 3.1264901097944655, 3.3963455817829411, 3.6025173553043817, 3.3174998295235265, 3.1727927941002649, 3.2450569837439818, 3.5973006502192919, 3.404899281966022, 3.3562486976501855, 3.1546843532113633, 3.2757670008320305, 3.6098345828561125, 3.190445191723895, 3.5756367399442723, 3.1262515129893247, 3.1470645985333632, 3.3942936313356604, 3.3439636970594315, 3.3032670335365668, 3.6084345726294034, 3.0664477702378963, 3.1199368798063376, 3.5041343650792172, 3.3510018962567272, 3.5497456168076202, 3.3198989128335268, 3.3320946350525369, 3.3157417192246621, 3.4339287926360971, 3.1866737312390851, 3.5882449282726796, 3.1448710575097083, 3.5452450776133522, 3.6407478633577681, 3.4312299016712298, 3.1409417007562994, 3.487989668095647, 3.1932929373021723, 3.6266408379283517, 3.2726225630175465, 3.4592740336566004, 3.3898192402082685, 3.3174179005410029, 3.3923892995316396, 3.5127902823869621, 3.0597081170052958, 3.5062367096658313, 3.4195632377993253, 3.352592864841426, 3.4674259584232727, 3.5087338691116656, 3.4944213375475668, 3.137648482064491, 3.32665765904903, 3.2233855201066, 3.4691796911145674, 3.3538239445982247, 3.6352630608857002, 3.4146384102614626, 3.5172295795756368, 3.3817432876522266, 3.2573385070616245, 3.3476184566964649, 3.0748850184363401, 3.2126660433391532, 3.4983770210300231, 3.6107791736471029, 3.3378785673385996, 3.3248025510245958, 3.355042427129117, 3.4857998782985176, 3.1654855774319763, 3.3312935082958628, 3.6645110190408876, 3.4919806106445925, 3.2386603269477825, 3.2618970801131471, 3.6106334005644709, 3.2833569060475307, 3.4152614384414521, 3.079030126743008])\n",
      "('mean return', 3.3525088784251285)\n",
      "('std of return', 0.15493133155964348)\n",
      "Agent data pickled successfully\n",
      "loading and building expert policy\n",
      "('obs', (1, 11), (1, 11))\n",
      "loaded and built\n",
      "(3749, 11)\n",
      "WARNING:tensorflow:From tf_util.py:91: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-28 17:17:05,341] From tf_util.py:91: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From tf_util.py:92: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-28 17:17:05,342] From tf_util.py:92: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "(10224932, 1, 3)\n",
      "(10224932, 11)\n",
      "Data mean is: [  1.40310727e+00  -6.88182004e-03  -1.11049251e-01  -5.71447489e-01\n",
      "   2.88128503e-01   2.78367951e+00   4.64378410e-02  -4.14444474e-04\n",
      "  -8.67950539e-03  -1.02232249e-01   1.68187284e-01]\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "num_rollouts = 200\n",
    "num_cycles = 3\n",
    "beta = 0.001\n",
    "path = './dagger_policy'\n",
    "\n",
    "# Network Parameters\n",
    "hidden1_units = 128 # 1st layer number of features\n",
    "hidden2_units = 128 # 2nd layer number of features\n",
    "\n",
    "environments = {1: \"Ant-v1\", 2: \"HalfCheetah-v1\", 3: \"Hopper-v1\", \n",
    "                4: \"Humanoid-v1\", 5: \"Reacher-v1\", 6: \"Walker2d-v1\"}\n",
    "environment = environments[3]\n",
    "env = gym.make(environment)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "main(num_cycles,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
